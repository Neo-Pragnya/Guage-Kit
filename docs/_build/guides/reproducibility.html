

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Reproducibility in Evaluations &mdash; Guage-Kit  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Guage-Kit API" href="../api/index.html" />
    <link rel="prev" title="Choosing Metrics for Evaluation" href="choosing_metrics.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Guage-Kit
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installing.html">Installing Guage-Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm_metrics.html">LLM Metrics in Guage-Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="rag_metrics.html">RAG Metrics Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="embeddings_metrics.html">Embeddings Metrics Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="choosing_metrics.html">Choosing Metrics for Evaluation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Reproducibility in Evaluations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#key-principles">Key Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configuration-example">Configuration Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-evaluations">Running Evaluations</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">Guage-Kit API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Guage-Kit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Reproducibility in Evaluations</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/guides/reproducibility.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="reproducibility-in-evaluations">
<h1>Reproducibility in Evaluations<a class="headerlink" href="#reproducibility-in-evaluations" title="Link to this heading"></a></h1>
<p>Reproducibility is a critical aspect of evaluating machine learning models, particularly in the context of LLMs (Large Language Models), RAG (Retrieval-Augmented Generation) systems, and embeddings. This document outlines the principles and practices to ensure that evaluations can be reliably reproduced.</p>
<section id="key-principles">
<h2>Key Principles<a class="headerlink" href="#key-principles" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p><strong>Seeded Metrics</strong>: All stochastic processes in the evaluation should be seeded with a fixed random seed. This ensures that results can be replicated across different runs. Users should be able to specify the seed in the configuration.</p></li>
<li><p><strong>Bootstrap Confidence Intervals</strong>: To provide a measure of uncertainty in the evaluation metrics, bootstrap confidence intervals (CIs) should be calculated. Users can enable this feature by specifying the number of bootstrap samples in the configuration.</p></li>
<li><p><strong>Artifact Management</strong>: All evaluation results, including metrics and reports, should be saved as artifacts. This allows users to revisit previous evaluations and compare results over time. The system should provide a clear structure for storing these artifacts.</p></li>
<li><p><strong>Version Control</strong>: It is essential to keep track of the versions of the models, datasets, and evaluation scripts used in the evaluation. This can be achieved by including version information in the evaluation reports and artifacts.</p></li>
<li><p><strong>Environment Consistency</strong>: The evaluation environment should be consistent across different runs. This includes using the same versions of libraries and dependencies. Users should be encouraged to use tools like <code class="docutils literal notranslate"><span class="pre">uv</span></code> to manage dependencies and ensure reproducibility.</p></li>
</ol>
</section>
<section id="configuration-example">
<h2>Configuration Example<a class="headerlink" href="#configuration-example" title="Link to this heading"></a></h2>
<p>Here is an example configuration that demonstrates how to set up reproducibility features:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># config.yaml</span>
<span class="nt">seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">42</span>
<span class="nt">bootstrap</span><span class="p">:</span>
<span class="w">  </span><span class="nt">n_samples</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span>
<span class="nt">report</span><span class="p">:</span>
<span class="w">  </span><span class="nt">html</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;reports/evaluation_report.html&quot;</span>
<span class="w">  </span><span class="nt">json</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;reports/evaluation_results.json&quot;</span>
</pre></div>
</div>
</section>
<section id="running-evaluations">
<h2>Running Evaluations<a class="headerlink" href="#running-evaluations" title="Link to this heading"></a></h2>
<p>When running evaluations, users should ensure that they specify the configuration file that includes the reproducibility settings. For example, using the command line interface:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>guage-kit<span class="w"> </span>run<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--data<span class="w"> </span>data/evaluation_data.jsonl<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--metrics<span class="w"> </span>retrieval@10<span class="w"> </span>mrr<span class="w"> </span>ndcg@10<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--config<span class="w"> </span>config.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--report-html<span class="w"> </span>reports/evaluation_report.html<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--report-json<span class="w"> </span>reports/evaluation_results.json
</pre></div>
</div>
<p>By following these principles and practices, users can ensure that their evaluations are reproducible, facilitating better understanding and trust in the results obtained from the Guage-Kit toolkit.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="choosing_metrics.html" class="btn btn-neutral float-left" title="Choosing Metrics for Evaluation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../api/index.html" class="btn btn-neutral float-right" title="Guage-Kit API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Neo Pragnya.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>